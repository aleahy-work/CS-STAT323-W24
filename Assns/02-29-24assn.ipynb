{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef75625a-da55-4c83-ad1e-65784e23a485",
   "metadata": {},
   "source": [
    "# Some Pytorch Datasets and Models #\n",
    "\n",
    "The purpose of this assignment is develop image models using the pytorch framework, learn how to use existing image models using the pytorch hub, and see some limitations of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8185ecc-8a8c-430c-8006-2f351e1c6f97",
   "metadata": {},
   "source": [
    "# Problem 0 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31336428-9591-415f-bf64-910b05d74dcf",
   "metadata": {},
   "source": [
    "AlexNet is one example of a pre-trained image model, but there are many others.  In this exercise you will load the ResNet50 model and use it to try and classify an image that you have downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd44087-fa01-4f1b-ba50-b4f0d7feda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994d12db-7aab-4508-ac7a-578e25a12714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e3669-5fb4-4106-9420-2bdf7a1b84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.list('pytorch/vision')  # This lists all the models available on the pytorch/vision hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbc58b-d33c-4b22-bce0-ca1500bddb3c",
   "metadata": {},
   "source": [
    "**Task:** There are more than 1000 categories in the Imagenet. (See below.)  Pick one, and find an image representing it on the internet, and see if ResNet50 can classify it. \n",
    "\n",
    "**Warning:** Be sure to research the arguments for loading ResNet50 into pytorch. Make sure you have resized the image appropriately.  If you can't find any images on the internet, my wife is a conoisseur of cat pictures and I have placed pictures of our two cats in the Assns folder on the Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eca944-f79e-47c1-8c23-46df04125150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "x = requests.get('https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt')\n",
    "print(x.text)  # This shows all the categories in imagenet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762c89f-d03f-435a-a156-619ce5691e89",
   "metadata": {},
   "source": [
    "# Problem 1 #\n",
    "\n",
    "The goal in this problem is to see how well convolutional models perform when the data is transformed in obvious ways. We shall be using the MNIST data set, which you should import from torchvision.dataset.\n",
    "\n",
    "1. Create and train a convolutional neural network to classify the MNIST data.  Track your validation and training accuracy throughout your training, and find your accuracy on the MNIST test dataset.  Your network should consist of the following sequence of layers, which slightly modify the network on pages 473-482 of the textbook--or see [the author's github](https://github.com/rasbt/machine-learning-book/tree/main/ch14):\n",
    "\n",
    "+ A 2-D convolution with 16 feature maps, kernel size of 5 with a stride of **three** (how much padding?)\n",
    "+ A ReLU activation function\n",
    "+ A **mean** pool layer with kernel size 2 and stride **2**\n",
    "+ A 2-D convolution with 32 feature maps, kernel size of 3 with a stride of 1 (how much padding?)\n",
    "+ A ReLU activation function\n",
    "+ A **mean** pool layer with kernel size 2 and stride **2**\n",
    "+ A linear fully-connected layer with 512 nodes\n",
    "+ Include a 50% dropout factor as well\n",
    "\n",
    "2. Apply a transformation (from [torchvision.transforms](https://pytorch.org/vision/0.9/transforms.html)) which rotates each image counterclockwise by 60 degrees.\n",
    "+ Produce a plot of a random sample of 10 elements of the newly transformed dataset\n",
    "+ Find the accuracy score of your model on this new dataset.  Does rotating the data seem to have an impact on your accuracy?\n",
    "\n",
    "3. Try the same thing with an [affine transformation](https://www.mathworks.com/discovery/affine-transformation.html), with any random rotation, a translation of at most 3, and a shear of at most 30 degrees, but no scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f014b9f-b6cf-488e-a974-fc487399ba50",
   "metadata": {},
   "source": [
    "# Problem 2 #\n",
    "\n",
    "In class on Wednesday we went over the \"Smile Classification\" problem of using a CNN to determine if a celebrity image represented a smiling face.  This is covered on pages 482-497 of Chapter 14 of the textbook, and in [part 2](https://github.com/rasbt/machine-learning-book/tree/main/ch14) of the accompanying Jupyter notebook.  In all of the times that I've trained this model, validation accuracy tops out at about 88%.  On page 497, the author issues a challenge: Try and get validation accuracy above 90%.  He suggests several approaches that you might try:\n",
    "\n",
    "+ Change the dropout probabilities and the number of filters in the different convolutional layers\n",
    "+ Replace the global average-pooling (see page 492) with a fully connected layer\n",
    "+ Overall, just see what happens if you change or modify the CNN architecture\n",
    "\n",
    "And if that doesn't work, he's fairly confident that \"if you are using the entire training dataset with the CNN archiecture we trained in thie chapter, you should be able to achieve about 90% accuracy\".\n",
    "\n",
    "**Task:** Take him up on the challenge and see if you can obtain more than 90% accuracy on your last validation rounds.\n",
    "\n",
    "**Note:**  To make the data easier to access, I have made a copy of the **celeba** dataset available in each of your math.knox.edu 'cloud' Jupyter notebook servers.  It is available in the folder '/data'.  You don't have to know the details, but you should know that the following code should load the **celeba** dataset for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce401fcf-2a67-4683-854c-42692738c8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 162770\n",
      "Validation set: 19867\n",
      "Test set: 19962\n"
     ]
    }
   ],
   "source": [
    "import torchvision \n",
    "\n",
    "image_path = '/data'\n",
    "celeba_train_dataset = torchvision.datasets.CelebA(image_path, split='train', target_type='attr', download=False)\n",
    "celeba_valid_dataset = torchvision.datasets.CelebA(image_path, split='valid', target_type='attr', download=False)\n",
    "celeba_test_dataset = torchvision.datasets.CelebA(image_path, split='test', target_type='attr', download=False)\n",
    "\n",
    "print('Train set:', len(celeba_train_dataset))\n",
    "print('Validation set:', len(celeba_valid_dataset))\n",
    "print('Test set:', len(celeba_test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df2dac-bd36-4811-ba06-cb0fc87e7600",
   "metadata": {},
   "source": [
    "**Warning:** The '/data' folder is **NOT** on the same computer system as the GPU processors, though the server *is* on the same network.  When files are shared over a network using this approach it takes additional time to load the data, so it *will* cause the model to train somewhat more slowly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff3332-8181-4335-a5e9-6fde7a4c00c3",
   "metadata": {},
   "source": [
    "# Problem 3 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d90c2-6984-4cea-baaf-66113385b262",
   "metadata": {},
   "source": [
    "The following code reads a file which contains the list of 40 attributes that are associated with each image in the **celeba** dataset.  Note that entry '31' is the 'Smiling' attribute we used in class.\n",
    "\n",
    "**Task:** Pick another attribute and use a neural network (perhaps the one from the text or the one you made in Problem 2) to make predictions for one of the other attributes in the list.  No need to produce a test dataset, but show your validation accuracy in the output of your training loop **and** produce a sample list of 10 images and probabilities as was done in the book.\n",
    "\n",
    "**Warning:** I don't how good any of these variables are.  It seems to me that \"Big_Nose\", for instance, is a rather subjective concept. Choose wisely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da428465-7dc1-409c-9957-16c047872dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/celeba/list_attr_celeba.txt') as f:\n",
    "    first_line = f.readline()\n",
    "    second_line = f.readline()\n",
    "\n",
    "myattributes = second_line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f077c810-f20a-49fb-9390-338e217b6414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_o_Clock_Shadow',\n",
       " 'Arched_Eyebrows',\n",
       " 'Attractive',\n",
       " 'Bags_Under_Eyes',\n",
       " 'Bald',\n",
       " 'Bangs',\n",
       " 'Big_Lips',\n",
       " 'Big_Nose',\n",
       " 'Black_Hair',\n",
       " 'Blond_Hair',\n",
       " 'Blurry',\n",
       " 'Brown_Hair',\n",
       " 'Bushy_Eyebrows',\n",
       " 'Chubby',\n",
       " 'Double_Chin',\n",
       " 'Eyeglasses',\n",
       " 'Goatee',\n",
       " 'Gray_Hair',\n",
       " 'Heavy_Makeup',\n",
       " 'High_Cheekbones',\n",
       " 'Male',\n",
       " 'Mouth_Slightly_Open',\n",
       " 'Mustache',\n",
       " 'Narrow_Eyes',\n",
       " 'No_Beard',\n",
       " 'Oval_Face',\n",
       " 'Pale_Skin',\n",
       " 'Pointy_Nose',\n",
       " 'Receding_Hairline',\n",
       " 'Rosy_Cheeks',\n",
       " 'Sideburns',\n",
       " 'Smiling',\n",
       " 'Straight_Hair',\n",
       " 'Wavy_Hair',\n",
       " 'Wearing_Earrings',\n",
       " 'Wearing_Hat',\n",
       " 'Wearing_Lipstick',\n",
       " 'Wearing_Necklace',\n",
       " 'Wearing_Necktie',\n",
       " 'Young']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myattributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7482eb9b-af71-4b42-bcca-c5e58751c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Smiling'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myattributes[31]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
