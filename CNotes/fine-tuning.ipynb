{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ebe462-9988-4624-b253-f4f17baa7fba",
   "metadata": {},
   "source": [
    "# The Textbook Fine-Tuning Tutorial #\n",
    "\n",
    "The original tutorial is from pages 574-586 of the textbook--see also ch16-part3-bert.ipynb on the [author's github](https://github.com/rasbt/machine-learning-book)--but I have made some significant deviations from this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52274626-32a6-49c4-847f-947cf6a1fc20",
   "metadata": {},
   "source": [
    "## The BERT model ##\n",
    "\n",
    "The BERT model is discussed on pages 569-572 of the textbook.  It is an interesting alternative to GPT--which is pre-trained solely on 'next token' prediction--in that it is trained primarily on (1) next sentence prediction and (2) masked language modeling.  The idea behind masked language modeling is that a token (essentially, 'word') in a sentence is replaced randomly by a '<mask>' token and the model attempts to predict what token has been masked.\n",
    "\n",
    "The idea is that this form of training makes it better able to understand 'contexts' that the next-word-predicting GPT models. Hence it is good for sentence classification (among other things).\n",
    "\n",
    "*In fact*, we will use a simplified version of the BERT model called DistilBERT. (More later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53720777-9dab-49be-97b4-84adc440fed3",
   "metadata": {},
   "source": [
    "## Loading Datasets ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "658399c9-9e45-4bc7-aa47-9f994f4e4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb6baf-8978-40b1-96df-13a1e4a086b3",
   "metadata": {},
   "source": [
    "There is a Huggingface page [completely devoted to this topic](https://huggingface.co/docs/datasets/en/index).  \n",
    "\n",
    "The primary class is [Dataset](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset).\n",
    "\n",
    "Loading and listing methods are [available directly through the datasets package](https://huggingface.co/docs/datasets/en/package_reference/loading_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f32f4-3ef3-4433-946e-975bd76b3893",
   "metadata": {},
   "source": [
    "### Example: IMDB ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "90110c98-deaa-4d92-93a6-72f9d829d67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plain_text']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.get_dataset_config_names('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "13c64655-e9ef-4f2a-8481-27a86b9d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "982b493b-91e6-4f12-820f-e097bd1adc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9ed0a794-38e4-489d-9490-4d5c60b3f756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b53bcf9d-63f1-4158-b65d-ffa8b6fe1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label'],\n",
       " 'test': ['text', 'label'],\n",
       " 'unsupervised': ['text', 'label']}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f8079faa-064c-44b2-ae4b-9ca48a57984e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['train']['label'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f1a3da4-630d-4e9b-a86a-5451cb40e54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['train']['text'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4737b2-e5fe-41e0-a8f1-c1e088d7e2af",
   "metadata": {},
   "source": [
    "### Example: tweet_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26134059-2f11-4bcd-90ad-067db4174a26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Config name is missing.\nPlease pick one among the available configs: ['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary']\nExample of usage:\n\t`load_dataset('tweet_eval', 'emoji')`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet_eval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py:2556\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2552\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2553\u001b[0m )\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2556\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py:2265\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2263\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;66;03m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 2265\u001b[0m builder_instance: DatasetBuilder \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mhash\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuilder_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2279\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39m_use_legacy_cache_dir_if_possible(dataset_module)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:371\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_dir\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_builder_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py:577\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_kwargs:\n\u001b[1;32m    576\u001b[0m         example_of_usage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_dataset(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig name is missing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease pick one among the available configs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder_configs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExample of usage:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_of_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     builder_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBUILDER_CONFIGS[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Config name is missing.\nPlease pick one among the available configs: ['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary']\nExample of usage:\n\t`load_dataset('tweet_eval', 'emoji')`"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tweet_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d91c98bc-4075-4a3a-97e1-0807a194a731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emoji',\n",
       " 'emotion',\n",
       " 'hate',\n",
       " 'irony',\n",
       " 'offensive',\n",
       " 'sentiment',\n",
       " 'stance_abortion',\n",
       " 'stance_atheism',\n",
       " 'stance_climate',\n",
       " 'stance_feminist',\n",
       " 'stance_hillary']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.get_dataset_config_names('tweet_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7c4c167-3a18-4f8b-91ec-b50b636ba6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 28.1k/28.1k [00:00<00:00, 54.1kB/s]\n",
      "Downloading data: 100%|██████████| 14.9k/14.9k [00:00<00:00, 72.9kB/s]\n",
      "Downloading data: 100%|██████████| 5.47k/5.47k [00:00<00:00, 23.0kB/s]\n",
      "Generating train split: 100%|██████████| 355/355 [00:00<00:00, 62365.57 examples/s]\n",
      "Generating test split: 100%|██████████| 169/169 [00:00<00:00, 48855.01 examples/s]\n",
      "Generating validation split: 100%|██████████| 40/40 [00:00<00:00, 11608.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset2 = load_dataset('tweet_eval', 'stance_climate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f5353f4-54b8-428f-b64e-d28e31beada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'label'],\n",
       " 'test': ['text', 'label'],\n",
       " 'validation': ['text', 'label']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b75742-248e-4b00-8a73-cb699d3eda50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"It's nights like this when I'm not so fond of my long hair. I just wanna chop it all off! #heatwave #pnwgirl #SemST\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "274cafb4-7af8-4e8b-a93c-e61112344474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why Is The Pope Upset?  via @user #UnzippedTruth #PopeFrancis #SemST',\n",
       " \"We support Australia's Climate Roundtable which is providing a framework for sensible debate ahead of Paris @user #SemST\",\n",
       " \"It's nights like this when I'm not so fond of my long hair. I just wanna chop it all off! #heatwave #pnwgirl #SemST\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['train']['text'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5183053e-1e21-4e75-a0bf-e987e1dd3da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['train']['label'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1485dda-2528-41ef-ac7a-f735d9f397cd",
   "metadata": {},
   "source": [
    "**Note:**  You can find all this information through the API, but it's probably easiest to go to the datacard through the Huggingface [Datasets link](https://huggingface.co/datasets/tweet_eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238984c-f409-40ff-a99e-7432e61e52c1",
   "metadata": {},
   "source": [
    "### Train/Test Split for IMDB ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f4333-7875-4135-9395-16426852cc21",
   "metadata": {},
   "source": [
    "Recall that the dataset is already split into test and train.  The next step is to split the train data into train and validation datasets (about 10% for our example).  Huggingface has a [train_test_split](https://huggingface.co/docs/datasets/v2.18.0/en/package_reference/main_classes#datasets.Dataset.train_test_split) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "596d7032-37ff-404b-a8dc-9da9f1c91702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70607780-2269-43e1-98ba-5a72616e1432",
   "metadata": {},
   "source": [
    "**Idea:** We will split the *train* dataset to include a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8337cd61-1820-4725-9e9d-d10d583c3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid = dataset1['train'].train_test_split(test_size=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "275c8485-2d19-4d3b-a081-4b5c9c5f60b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 22500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a6db4-72e6-4303-b66e-ea3540570c6e",
   "metadata": {},
   "source": [
    "Note this still has the same structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09accaec-bcef-49a5-b760-37617ef1c2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"With these people faking so many shots, using old footage, and gassing animals to get them out, not to mention that some of the scenes were filmed on a created set with actors, what's to believe? Old film of countries is nice, but the animal abuse and degradation of natives is painful to watch in these films. I know, racism is OK in these old films, but there is more to that to make this couple lose credibility. Portrayed as fliers, they never flew their planes, Martin Johnson was an ex-vaudevillian, used friends like Jack London for financial gain while stiffing them of royalties, denying his wife's apparent depression, using her as a cute prop, all this makes these films unbearable. They were by no means the first to travel to these lands, or the first to write about them. He was OK as a filmmaker and photographer, but that's about it.\",\n",
       " \"I don't know the stars, or modern Chinese teenage music - but I do know a thoroughly entertaining movie when I see one.<br /><br />Kung Fu Dunk is pure Hollywood in its values - it's played for laughs, for love, and is a great blend of Kung Fu and basketball.<br /><br />Everybody looks like they had a lot of fun making this - the production values are excellent - and modern China looks glossier than Los Angeles here.<br /><br />The plot of the abandoned orphan who grows up in a kung fu school only to be kicked out and then discover superstardom as a basketball play (and love and more etc;) is great - this is fresh, fun, and immensely entertaining.<br /><br />With great action and good dialogue this is one simply to enjoy - for all ages - and for our money was one of the best family movies we're seen in a long time.<br /><br />Please ignore the negative reviews and give Dunk a chance - we were really glad we did - a GOOD sports comedy movie.\"]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid['train']['text'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4e08ccba-f279-4d3b-adc9-82a3ebaacaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain = train_valid['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "027b716d-d256-45c6-a561-904fa4ed02e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"With these people faking so many shots, using old footage, and gassing animals to get them out, not to mention that some of the scenes were filmed on a created set with actors, what's to believe? Old film of countries is nice, but the animal abuse and degradation of natives is painful to watch in these films. I know, racism is OK in these old films, but there is more to that to make this couple lose credibility. Portrayed as fliers, they never flew their planes, Martin Johnson was an ex-vaudevillian, used friends like Jack London for financial gain while stiffing them of royalties, denying his wife's apparent depression, using her as a cute prop, all this makes these films unbearable. They were by no means the first to travel to these lands, or the first to write about them. He was OK as a filmmaker and photographer, but that's about it.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4fcd0543-15d4-47f5-96e5-6a862138aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "myvalid = train_valid['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f215f98-978a-4a87-9344-eee29e0018c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvalid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aeeb58-35bb-459b-a18e-60530815fb0d",
   "metadata": {},
   "source": [
    "We have to transform our data into a format that can be used by the model.   This is accomplished by a [Huggingface Tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer).  Huggingface models have tokenizers that produce the appropriate tokens.  The Distilbert tokenizer is described on the [Distilbert page](https://huggingface.co/docs/transformers/model_doc/distilbert)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eef9fe-d960-4dba-8f85-8e4eeeee479b",
   "metadata": {},
   "source": [
    "### Tokenizing the Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "18995c62-d16d-4b18-a94d-dbfa6ae20414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0977951a-25c6-41a7-a15d-36ca9246fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba3f78-c269-4e8e-9d31-cc0fd48c0de2",
   "metadata": {},
   "source": [
    "**Note:** This seems rather awkward, but most HuggingFace fine-tuning tutorials I've seen make use of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a0b8363f-275c-4495-8b37-227716dd391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6464f275-58d3-44c3-8a39-58612144b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 22500/22500 [00:04<00:00, 5083.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokened = mytrain.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e93c6-f34d-4359-ac57-6fa3c4b8d894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tokened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5ee39813-04d0-449c-8702-c2e1a2136af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 5300.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "valid_tokened = myvalid.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d27a3-f7d8-41b2-9dcb-5feac7c9164e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_tokened[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42fe2d-43e3-4234-a1f0-29f3cd7645e1",
   "metadata": {},
   "source": [
    "## Fine-tuning with the Trainer API ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59939cb4-49bf-42a8-9eb4-3597846d9a1d",
   "metadata": {},
   "source": [
    "We will use the 'distilbert-base-uncased' model.  This is available from the [Huggingface models page](https://huggingface.co/models). See the model card page at that URL.  See also the [DistilBert page](https://huggingface.co/docs/transformers/model_doc/distilbert), which discusses the [sequence classification head](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "203cb02c-d23b-4523-ad2a-4f9a6db7623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16502f1c-1293-410b-926d-c272783054e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ca1aa-f022-4deb-9020-38aa5b7bc191",
   "metadata": {},
   "source": [
    "**Note:**  This last step is unnecessary.  If we are using  the Trainer class with Pytorch, the GPU is used automatically by the software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6b2a2f4-7fbb-433d-a71c-e45167876d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fcdb3-b44e-40c2-8a90-5a331fbf8288",
   "metadata": {},
   "source": [
    "### The Huggingface Trainer Class ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d9ca0-a5e7-4533-a3c4-84fe1dbedac8",
   "metadata": {},
   "source": [
    "The Huggingface [Trainer class](https://huggingface.co/docs/transformers/en/main_classes/trainer) specifies a [Trainer](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/trainer#transformers.Trainer).  The basic inputs for this are the model and the dataset, but the most complicated part is specifying the [TrainingArguments](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/trainer#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "90751213-1b03-435e-a8ac-fe7e3803c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', \n",
    "    num_train_epochs=3,     \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,   \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokened,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14764861-326d-4df2-97d9-26ed70b94336",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dcd4b781-fc6d-4bd1-bf3b-443f76a2830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', \n",
    "    num_train_epochs=3,     \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,   \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=16,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokened,\n",
    "    eval_dataset=valid_tokened\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d0e46-d79a-4320-be1c-cc413fe98a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b82fe8-6f97-4231-a8cb-071ce18e412e",
   "metadata": {},
   "source": [
    "**Note:** The trainer API only shows *training loss* and not *model evaluation* (e.g., accuracy).  However, you can *define* a separate model evaluation function.  We can add a 'compute_metrics' function to change that.  This function uses the model predictions \"as logits\" and compares them to test labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be39a0-65b3-430c-9268-d62f14b5a121",
   "metadata": {},
   "source": [
    "## Better Model Evaluation ##\n",
    "\n",
    "See [this page](https://huggingface.co/docs/datasets/metrics) on the Huggingface site.  \n",
    "Each 'Metric' objection  has a [compute method](https://huggingface.co/docs/datasets/v2.18.0/en/package_reference/main_classes#datasets.Metric.compute).\n",
    "\n",
    "**Note:** The first paragraphs warns that the 'metrics' class is deprecated, and they are transitioning the the [evaluation class](https://huggingface.co/docs/evaluate/index).  Tutorials will probably have a mixture of both, so **be careful**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a613b78-8b6a-4f56-a3e9-49e19658d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1303/3713065601.py:2: FutureWarning: list_metrics is deprecated and will be removed in the next major version of datasets. Use 'evaluate.list_evaluation_modules' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metrics_list = list_metrics()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score', 'cer', 'character', 'charcut_mt', 'chrf', 'code_eval', 'comet', 'competition_math', 'confusion_matrix', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'mape', 'mase', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'nist_mt', 'pearsonr', 'perplexity', 'poseval', 'precision', 'r_squared', 'recall', 'rl_reliability', 'roc_auc', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'smape', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'trec_eval', 'wer', 'wiki_split', 'xnli', 'xtreme_s', 'Aledade/extraction_evaluation', 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'Bekhouche/NED', 'BucketHeadP65/confusion_matrix', 'BucketHeadP65/roc_curve', 'CZLC/rouge_raw', 'DaliaCaRo/accents_unplugged_eval', 'DarrenChensformer/eval_keyphrase', 'DarrenChensformer/relation_extraction', 'DoctorSlimm/bangalore_score', 'DoctorSlimm/kaushiks_criteria', 'Drunper/metrica_tesi', 'Felipehonorato/eer', 'Fritz02/execution_accuracy', 'GMFTBY/dailydialog_evaluate', 'GMFTBY/dailydialogevaluate', 'He-Xingwei/sari_metric', 'Ikala-allen/relation_extraction', 'JP-SystemsX/nDCG', 'Josh98/nl2bash_m', 'KevinSpaghetti/accuracyk', 'LottieW/accents_unplugged_eval', 'LuckiestOne/valid_efficiency_score', 'Merle456/accents_unplugged_eval', 'Muennighoff/code_eval_octopack', 'NCSOFT/harim_plus', 'Natooz/ece', 'Ndyyyy/bertscore', 'NikitaMartynov/spell-check-metric', 'NimaBoscarino/weat', 'Ochiroo/rouge_mn', 'Pipatpong/perplexity', 'Qui-nn/accents_unplugged_eval', 'RiciHuggingFace/accents_unplugged_eval', 'SEA-AI/det-metrics', 'SEA-AI/mot-metrics', 'Soroor/cer', 'SpfIo/wer_checker', 'Splend1dchan/cosine_similarity', 'TelEl/accents_unplugged_eval', 'Vallp/ter', 'Vertaix/vendiscore', 'Vickyage/accents_unplugged_eval', 'Viona/fuzzy_reordering', 'Viona/infolm', 'Viona/kendall_tau', 'Vipitis/shadermatch', 'Vlasta/pr_auc', 'Yeshwant123/mcc', 'abdusah/aradiawer', 'abidlabs/mean_iou', 'abidlabs/mean_iou2', 'agkphysics/ccc', 'akki2825/accents_unplugged_eval', 'alvinasvk/accents_unplugged_eval', 'amitness/perplexity', 'andstor/code_perplexity', 'angelasophie/accents_unplugged_eval', 'angelina-wang/directional_bias_amplification', 'anz2/iliauniiccocrevaluation', 'arthurvqin/pr_auc', 'aryopg/roc_auc_skip_uniform_labels', 'bascobasculino/mot-metrics', 'bdsaglam/jer', 'boschar/accents_unplugged_eval', 'brian920128/doc_retrieve_metrics', 'bstrai/classification_report', 'bugbounty1806/accuracy', 'cakiki/ndcg', 'carletoncognitivescience/peak_signal_to_noise_ratio', 'chanelcolgate/average_precision', 'chimene/accents_unplugged_eval', 'ckb/unigram', 'codeparrot/apps_metric', 'cpllab/syntaxgym', 'd-matrix/dmx_perplexity', 'daiyizheng/valid', 'danieldux/hierarchical_softmax_loss', 'danieldux/isco_hierarchical_accuracy', 'danieldux/my_git_test_module', 'dayil100/accents_unplugged_eval', 'dayil100/accents_unplugged_eval_WER', 'dgfh76564/accents_unplugged_eval', 'dvitel/codebleu', 'ecody726/bertscore', 'erntkn/dice_coefficient', 'fnvls/bleu1234', 'fnvls/bleu_1234', 'franzi2505/detection_metric', 'fschlatt/ner_eval', 'gabeorlanski/bc_eval', 'giulio98/code_eval_outputs', 'giulio98/codebleu', 'gjacob/bertimbauscore', 'gjacob/chrf', 'gjacob/google_bleu', 'gjacob/wiki_split', 'gnail/cosine_similarity', 'gorkaartola/metric_for_tp_fp_samples', 'guydav/restrictedpython_code_eval', 'hack/test_metric', 'harshhpareek/bertscore', 'hpi-dhc/FairEval', 'huanghuayu/multiclass_brier_score', 'hynky/sklearn_proxy', 'hyperml/balanced_accuracy', 'iNeil77/code_eval_octopack', 'idsedykh/codebleu', 'idsedykh/codebleu2', 'idsedykh/megaglue', 'idsedykh/metric', 'illorca/FairEval', 'ingyu/klue_mrc', 'jialinsong/apps_metric', 'jjkim0807/code_eval', 'jordyvl/ece', 'jpxkqx/peak_signal_to_noise_ratio', 'jpxkqx/signal_to_reconstruction_error', 'juliakaczor/accents_unplugged_eval', 'jzm-mailchimp/joshs_second_test_metric', 'k4black/codebleu', 'kashif/mape', 'kedudzic/charmatch', 'kyokote/my_metric2', 'langdonholmes/cohen_weighted_kappa', 'leslyarun/fbeta_score', 'lhy/hamming_loss', 'lhy/ranking_loss', 'livvie/accents_unplugged_eval', 'loubnabnl/apps_metric2', 'lvwerra/accuracy_score', 'lvwerra/bary_score', 'lvwerra/test', 'maksymdolgikh/seqeval_with_fbeta', 'manueldeprada/beer', 'mfumanelli/geometric_mean', 'mgfrantz/roc_auc_macro', 'mtc/fragments', 'nevikw39/specificity', 'nlpln/tst', 'ola13/precision_at_k', 'omidf/squad_precision_recall', 'posicube/mean_reciprocal_rank', 'red1bluelost/evaluate_genericify_cpp', 'repllabs/mean_average_precision', 'repllabs/mean_reciprocal_rank', 'ronaldahmed/nwentfaithfulness', 'saicharan2804/my_metric', 'sakusakumura/bertscore', 'shalakasatheesh/squad', 'shalakasatheesh/squad_v2', 'shirayukikun/sescore', 'shunzh/apps_metric', 'sma2023/wil', 'sportlosos/sescore', 'transZ/sbert_cosine', 'transZ/test_parascore', 'transformersegmentation/segmentation_scores', 'unitxt/metric', 'unnati/kendall_tau_distance', 'vichyt/metric-codebleu', 'weiqis/pajm', 'xu1998hz/sescore', 'xu1998hz/sescore_english_coco', 'xu1998hz/sescore_english_mt', 'xu1998hz/sescore_english_webnlg', 'xu1998hz/sescore_german_mt', 'ybelkada/cocoevaluate', 'yonting/average_precision_score', 'yqsong/execution_accuracy', 'yulong-me/yl_metric', 'yuyijiong/quad_match_score', 'yzha/ctc_eval', 'zbeloki/m2']\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_metrics\n",
    "metrics_list = list_metrics()\n",
    "len(metrics_list)\n",
    "print(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55eb988-7e5e-403b-8b76-e2baddeea2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccec1423-6871-41e4-ab6b-3921d3bde41a",
   "metadata": {},
   "source": [
    "**Note:** More details on individual metrics can be found [here](https://huggingface.co/metrics).   We will use the accuracy metric, which is described in the [Huggingface documentation](https://huggingface.co/spaces/evaluate-metric/accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6ffa5375-04ab-401c-bd58-e9c6d088f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred # logits are a numpy array, not pytorch tensor\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(\n",
    "               predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0295b8c7-8458-4415-83f3-c9747c838501",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', \n",
    "    num_train_epochs=3,     \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,   \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokened,\n",
    "    eval_dataset=valid_tokened,\n",
    "    optimizers=(optim, None) # optimizer and learning rate scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5262b-60d0-4af1-a2ac-99ee91ec5241",
   "metadata": {},
   "source": [
    "**Note:**  The example below gives a way to *time* your training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a67d84ef-9659-42fc-aeeb-7b520bb0967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85241b-ff34-43c2-a4d0-523de786d183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "trainer.train()\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "41faf79f-d0c2-4995-893a-9360fba2cbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7392910718917847, 'eval_accuracy': 0.902}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "51480e0a-5829-4f0b-bcde-f449bce8d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results', \n",
    "    num_train_epochs=3,     \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,   \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokened,\n",
    "    eval_dataset=valid_tokened,\n",
    "    optimizers=(optim, None) # optimizer and learning rate scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "50f6979a-6e9d-4df5-93ae-9e18096d707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1437' max='4221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1437/4221 13:10 < 25:32, 1.82 it/s, Epoch 1.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.452670</td>\n",
       "      <td>0.903600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py:1966\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1966\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c815d3c-598b-4757-bd2e-f098928fe851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
